{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from IPython.display import display\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Append a path if needed\n",
    "sys.path.append(\"../\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are features with numerical or continuous values:\n",
    "age\n",
    "education-num\n",
    "capital-gain\n",
    "capital-loss\n",
    "hours-per-week\n",
    "\n",
    "The rest of the features are categorical and therefore not suitable for Disparate Impact Remover.\n",
    "\n",
    "DIR applies linear transformations to adjust feature values in the dataset. It aims to reduce the dependence of other features on the sensitive attribute (e.g., sex) while preserving the relative order of the data within each group. These transformations work well with continuous numerical features but encounter challenges with categorical features.Categorical features are often represented as discrete classes or labels (e.g., \"Male\" and \"Female\" or encoded as 0 and 1).\n",
    "Linear transformations, such as scaling or shifting values, cannot meaningfully modify these discrete categories because they don't represent a numerical continuum. A linear transformation might produce invalid or nonsensical values like \"1.5\" or \"0.7\".\n",
    "Numerical features (e.g., age, income) can be scaled, shifted, or transformed continuously while maintaining their interpretation and validity. This aligns perfectly with DIR’s mathematical framework, which is designed for numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole dataset with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RACE', 'SEX', 'PCS42', 'MCS42']\n"
     ]
    }
   ],
   "source": [
    "def further_preprocessing_aif360_no_categorical(meps_dataset):\n",
    "    \"\"\"\n",
    "    Further preprocess the MEPS dataset to prepare it for AIF360 analysis,\n",
    "    removing all categorical features.\n",
    "    \"\"\"\n",
    "    # Convert MEPSDataset19 to a DataFrame\n",
    "    df, metadata = meps_dataset.convert_to_dataframe()\n",
    "\n",
    "    # Step 1: Clean invalid values for PCS42 and MCS42\n",
    "    for col in ['PCS42', 'MCS42']:\n",
    "        if col in df.columns:\n",
    "            # Replace negative values with NaN\n",
    "            df[col] = df[col].apply(lambda x: pd.NA if x < 0 else x)\n",
    "            # Fill NaN values with the column median\n",
    "            df[col] = df[col].fillna(df[col].median(skipna=True))\n",
    "\n",
    "    #Scaling them prevents DIR to be effective on features that are tightly scaled around 0 with std ≈ 1. The repair process might not sufficiently disrupt patterns if all features are normalized to the same scale.\n",
    "    # Step 2: Scale numerical features\n",
    "    #scaler = StandardScaler()\n",
    "    #df[['PCS42', 'MCS42']] = scaler.fit_transform(df[['PCS42', 'MCS42']])\n",
    "\n",
    "    # Step 3: Rename SEX column and convert RACE\n",
    "    df.rename(columns={'SEX=1': 'SEX'}, inplace=True)\n",
    "    df['RACE'] = df['RACE'].replace({'White': 1.0, 'Non-White': 0.0})\n",
    "\n",
    "    # Step 4: Retain only numerical features\n",
    "    selected_columns = ['RACE', 'SEX', 'PCS42', 'MCS42', 'UTILIZATION']\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    # Step 5: Create the processed AIF360 dataset\n",
    "    processed_dataset = StandardDataset(\n",
    "        df,\n",
    "        label_name='UTILIZATION',\n",
    "        favorable_classes=[1.0],\n",
    "        protected_attribute_names=['RACE', 'SEX'],\n",
    "        privileged_classes=[[1.0], [1.0]],  # Privileged groups: White and Male\n",
    "    )\n",
    "\n",
    "    return processed_dataset\n",
    "\n",
    "\n",
    "# Instantiate MEPSDataset19\n",
    "meps = MEPSDataset19()\n",
    "\n",
    "# Apply further preprocessing\n",
    "processed_meps = further_preprocessing_aif360_no_categorical(meps)\n",
    "\n",
    "# Inspect the AIF360 dataset\n",
    "print(processed_meps.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PCS42</th>\n",
       "      <th>MCS42</th>\n",
       "      <th>UTILIZATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.999483</td>\n",
       "      <td>0.732604</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.658722</td>\n",
       "      <td>-3.418660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253640</td>\n",
       "      <td>-0.326684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291328</td>\n",
       "      <td>0.199056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291328</td>\n",
       "      <td>0.199056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683162</td>\n",
       "      <td>1.242728</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683162</td>\n",
       "      <td>1.242728</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16575</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291328</td>\n",
       "      <td>0.199056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.841104</td>\n",
       "      <td>-1.352137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16577</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995444</td>\n",
       "      <td>-1.220702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RACE  SEX     PCS42     MCS42  UTILIZATION\n",
       "0       1.0  1.0 -2.999483  0.732604          1.0\n",
       "1       1.0  0.0 -3.658722 -3.418660          1.0\n",
       "3       1.0  0.0  0.253640 -0.326684          0.0\n",
       "4       1.0  1.0  0.291328  0.199056          0.0\n",
       "5       0.0  1.0  0.291328  0.199056          0.0\n",
       "...     ...  ...       ...       ...          ...\n",
       "16573   0.0  1.0  0.683162  1.242728          0.0\n",
       "16574   0.0  0.0  0.683162  1.242728          0.0\n",
       "16575   1.0  0.0  0.291328  0.199056          0.0\n",
       "16576   0.0  0.0 -0.841104 -1.352137          0.0\n",
       "16577   0.0  0.0 -0.995444 -1.220702          0.0\n",
       "\n",
       "[15830 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, metadata = processed_meps.convert_to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'RACE': 1}]\n",
    "unprivileged_groups = [{'RACE': 0}]\n",
    "preprocessed_dataset = processed_meps\n",
    "train, val_test = preprocessed_dataset.split([0.7], shuffle=True)\n",
    "val, test = val_test.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset (Before Transformation):\n",
      "  Statistical Parity Difference: -0.1310\n",
      "  Disparate Impact: 0.4905\n",
      "\n",
      "Test Dataset (Before Transformation):\n",
      "  Statistical Parity Difference: -0.1256\n",
      "  Disparate Impact: 0.4876\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fairness metrics before applying bias mitigation\n",
    "metric_train = BinaryLabelDatasetMetric(train, unprivileged_groups, privileged_groups)\n",
    "print(\"Train Dataset (Before Transformation):\")\n",
    "print(f\"  Statistical Parity Difference: {metric_train.mean_difference():.4f}\")\n",
    "print(f\"  Disparate Impact: {metric_train.disparate_impact():.4f}\")\n",
    "\n",
    "metric_test = BinaryLabelDatasetMetric(test, unprivileged_groups, privileged_groups)\n",
    "print(\"\\nTest Dataset (Before Transformation):\")\n",
    "print(f\"  Statistical Parity Difference: {metric_test.mean_difference():.4f}\")\n",
    "print(f\"  Disparate Impact: {metric_test.disparate_impact():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_impact_remover = disparate_impact_remover = DisparateImpactRemover(repair_level= 1.0, sensitive_attribute=\"RACE\")\n",
    "\n",
    "# Fit and transform training data\n",
    "train_transf = disp_impact_remover.fit_transform(train)\n",
    "\n",
    "val_transf = disp_impact_remover.fit_transform(val) #transform is not supported for this class\n",
    "\n",
    "test_transf = disp_impact_remover.fit_transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Dataset (After Transformation):\n",
      "  Statistical Parity Difference: -0.1310\n",
      "  Disparate Impact: 0.4905\n",
      "\n",
      "Test Dataset (After Transformation):\n",
      "  Statistical Parity Difference: -0.1256\n",
      "  Disparate Impact: 0.4876\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fairness metrics after applying LFR\n",
    "metric_train_after = BinaryLabelDatasetMetric(train_transf, unprivileged_groups, privileged_groups)\n",
    "print(\"\\nTrain Dataset (After Transformation):\")\n",
    "print(f\"  Statistical Parity Difference: {metric_train_after.mean_difference():.4f}\")\n",
    "print(f\"  Disparate Impact: {metric_train_after.disparate_impact():.4f}\")\n",
    "\n",
    "metric_test_after = BinaryLabelDatasetMetric(test_transf, unprivileged_groups, privileged_groups)\n",
    "print(\"\\nTest Dataset (After Transformation):\")\n",
    "print(f\"  Statistical Parity Difference: {metric_test_after.mean_difference():.4f}\")\n",
    "print(f\"  Disparate Impact: {metric_test_after.disparate_impact():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               RACE           SEX         PCS42         MCS42   UTILIZATION\n",
      "count  11081.000000  11081.000000  11081.000000  11081.000000  11081.000000\n",
      "mean       0.353578      0.475047     50.955578     52.830665      0.172367\n",
      "std        0.478102      0.499400      8.378393      7.669662      0.377716\n",
      "min        0.000000      0.000000      7.330000      0.050000      0.000000\n",
      "25%        0.000000      0.000000     51.490000     52.000000      0.000000\n",
      "50%        0.000000      0.000000     53.435000     54.370000      0.000000\n",
      "75%        1.000000      1.000000     54.800000     56.570000      0.000000\n",
      "max        1.000000      1.000000     70.350000     75.510000      1.000000\n",
      "               RACE           SEX         PCS42         MCS42   UTILIZATION\n",
      "count  11081.000000  11081.000000  11081.000000  11081.000000  11081.000000\n",
      "mean       0.353578      0.475047     50.741063     52.760283      0.172367\n",
      "std        0.478102      0.499400      8.693872      7.675369      0.377716\n",
      "min        0.000000      0.000000      7.330000      0.050000      0.000000\n",
      "25%        0.000000      0.000000     51.340000     52.000000      0.000000\n",
      "50%        0.000000      0.000000     53.435000     54.360000      0.000000\n",
      "75%        1.000000      1.000000     54.790000     56.470000      0.000000\n",
      "max        1.000000      1.000000     69.490000     74.980000      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Example: Inspect feature distributions before and after applying DIR\n",
    "df_train_before, _ = train.convert_to_dataframe()\n",
    "df_train_after, _ = train_transf.convert_to_dataframe()\n",
    "print(df_train_before.describe())\n",
    "print(df_train_after.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the end to see the explanation as to why Statistical Parity Difference and Disparate Impact did not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Before Transformation:\n",
      "RACE           1.000000\n",
      "SEX            0.009361\n",
      "PCS42         -0.064497\n",
      "MCS42         -0.057078\n",
      "UTILIZATION    0.165758\n",
      "Name: RACE, dtype: float64\n",
      "Correlation After Transformation:\n",
      "RACE           1.000000\n",
      "SEX            0.009361\n",
      "PCS42         -0.054160\n",
      "MCS42         -0.053905\n",
      "UTILIZATION    0.165758\n",
      "Name: RACE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_before = df_train_before.corr()\n",
    "corr_after = df_train_after.corr()\n",
    "print(\"Correlation Before Transformation:\")\n",
    "print(corr_before['RACE'])\n",
    "print(\"Correlation After Transformation:\")\n",
    "print(corr_after['RACE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "train.features = scaler.fit_transform(train.features)\n",
    "val.features = scaler.transform(val.features)\n",
    "test.features = scaler.transform(test.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold (validation): 0.46\n",
      "Best Balanced Accuracy (validation): 0.7240373438624329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\festa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on original training data\n",
    "classifier.fit(train.features, train.labels.ravel())\n",
    "\n",
    "# Predict on validation set\n",
    "val_scores = classifier.predict_proba(val.features)[:, 1] #only for the favorable class\n",
    "\n",
    "# Select best threshold for validation set\n",
    "thresholds = np.arange(0.01, 1, 0.01)\n",
    "val_balanced_accs = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    val_LR_predictions = (val_scores >= threshold).astype(int)\n",
    "\n",
    "    val_with_LR_scores = copy.deepcopy(val)\n",
    "    val_with_LR_scores.labels = val_LR_predictions.reshape(-1, 1)  # Update labels with predictions\n",
    "\n",
    "    val_metric = ClassificationMetric(val, val_with_LR_scores,\n",
    "                                      unprivileged_groups=unprivileged_groups,\n",
    "                                      privileged_groups=privileged_groups)\n",
    "    balanced_acc = (val_metric.true_positive_rate() + val_metric.true_negative_rate()) / 2\n",
    "    disparate_impact = val_metric.disparate_impact()\n",
    "    avg_odds_diff = val_metric.average_odds_difference()\n",
    "\n",
    "    val_balanced_accs.append(balanced_acc)\n",
    "\n",
    "best_index = np.argmax(val_balanced_accs)\n",
    "best_threshold = thresholds[best_index]\n",
    "best_balanced_acc = val_balanced_accs[best_index]\n",
    "\n",
    "print(f\"Best Threshold (validation): {best_threshold}\")\n",
    "print(f\"Best Balanced Accuracy (validation): {best_balanced_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (test): 0.707691744787053\n",
      "Statistical Parity Difference (test): -0.44663998398427773\n",
      "Disparate Impact (test): 0.2564556588460971\n",
      "Average Odds Difference (test): -0.38133815014700395\n",
      "Equal Opportunity Difference (test): -0.3438184663536776\n",
      "Theil Index (test): 0.10829689972633931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply the best threshold to the test set\n",
    "test_scores = classifier.predict_proba(test.features)[:, 1]\n",
    "test_LR_predictions= (test_scores >= best_threshold).astype(int)\n",
    "\n",
    "# Create a copy of the test dataset and set predicted labels\n",
    "test_with_LR_scores = copy.deepcopy(test)\n",
    "test_with_LR_scores.labels = test_LR_predictions.reshape(-1, 1)\n",
    "\n",
    "# Calculate fairness and performance metrics on the test set\n",
    "test_metric = ClassificationMetric(test, test_with_LR_scores,\n",
    "                                   unprivileged_groups=unprivileged_groups,\n",
    "                                   privileged_groups=privileged_groups)\n",
    "\n",
    "# Balanced Accuracy\n",
    "true_positive_rate = test_metric.true_positive_rate()\n",
    "true_negative_rate = test_metric.true_negative_rate()\n",
    "balanced_accuracy = (true_positive_rate + true_negative_rate) / 2\n",
    "print(f\"Balanced Accuracy (test): {balanced_accuracy}\")\n",
    "\n",
    "# Statistical Parity Difference\n",
    "statistical_parity_difference = test_metric.statistical_parity_difference()\n",
    "print(f\"Statistical Parity Difference (test): {statistical_parity_difference}\")\n",
    "\n",
    "# Disparate Impact\n",
    "disparate_impact = test_metric.disparate_impact()\n",
    "print(f\"Disparate Impact (test): {disparate_impact}\")\n",
    "\n",
    "# Average Odds Difference\n",
    "average_odds_difference = test_metric.average_odds_difference()\n",
    "print(f\"Average Odds Difference (test): {average_odds_difference}\")\n",
    "\n",
    "# Equal Opportunity Difference\n",
    "equal_opportunity_difference = test_metric.equal_opportunity_difference()\n",
    "print(f\"Equal Opportunity Difference (test): {equal_opportunity_difference}\")\n",
    "\n",
    "# Theil Index\n",
    "theil_index = test_metric.theil_index()\n",
    "print(f\"Theil Index (test): {theil_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\festa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    }
   ],
   "source": [
    "# Plot Test Metrics Over Thresholds\n",
    "test_balanced_accs = []\n",
    "test_disp_impacts = []\n",
    "test_avg_odds_diffs = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    test_predictions = (test_scores >= threshold).astype(int)\n",
    "    test_with_scores = copy.deepcopy(test)\n",
    "    test_with_scores.labels = test_predictions.reshape(-1, 1)\n",
    "\n",
    "    test_metric = ClassificationMetric(test, test_with_scores, unprivileged_groups, privileged_groups)\n",
    "    test_balanced_accs.append((test_metric.true_positive_rate() + test_metric.true_negative_rate()) / 2)\n",
    "    test_disp_impacts.append(test_metric.disparate_impact())\n",
    "    test_avg_odds_diffs.append(test_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\festa\\AppData\\Local\\Temp\\ipykernel_25836\\1029601867.py:34: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create the figure and primary y-axis for Balanced Accuracy\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Balanced Accuracy\n",
    "ax1.plot(thresholds, test_balanced_accs, label=\"Balanced Accuracy\", color=\"blue\", linewidth=2)\n",
    "ax1.set_xlabel(\"Threshold\", fontsize=14)\n",
    "ax1.set_ylabel(\"Balanced Accuracy\", color=\"blue\", fontsize=14)\n",
    "ax1.tick_params(axis='y', labelcolor=\"blue\")\n",
    "ax1.grid()\n",
    "\n",
    "# Secondary y-axis for Disparate Impact and Equal Opportunity Difference\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Disparate Impact\n",
    "ax2.plot(thresholds, test_disp_impacts, label=\"Disparate Impact\", color=\"orange\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Average Odds Difference\n",
    "ax2.plot(thresholds, test_avg_odds_diffs, label=\"Average Odds Difference\", color=\"red\", linestyle=\"-.\", linewidth=2)\n",
    "\n",
    "ax2.set_ylabel(\"Fairness Metrics\", color=\"red\", fontsize=14)\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "\n",
    "# Highlight the best threshold\n",
    "ax1.axvline(best_threshold, color='green', linestyle='--', linewidth=2, label=\"Best Threshold\")\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(lines1 + lines2, labels1 + labels2, loc=\"upper center\", bbox_to_anchor=(0.5, -0.1), ncol=3, fontsize=12)\n",
    "\n",
    "# Title and layout adjustments\n",
    "fig.suptitle(\"Test Metrics vs Threshold (original test data)\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier on the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repair Level: 0.0 ===\n",
      "\n",
      "=== Repair Level: 0.1 ===\n",
      "\n",
      "=== Repair Level: 0.2 ===\n",
      "\n",
      "=== Repair Level: 0.30000000000000004 ===\n",
      "\n",
      "=== Repair Level: 0.4 ===\n",
      "\n",
      "=== Repair Level: 0.5 ===\n",
      "\n",
      "=== Repair Level: 0.6000000000000001 ===\n",
      "\n",
      "=== Repair Level: 0.7000000000000001 ===\n",
      "\n",
      "=== Repair Level: 0.8 ===\n",
      "\n",
      "=== Repair Level: 0.9 ===\n",
      "\n",
      "=== Repair Level: 1.0 ===\n",
      "\n",
      "Results for Various Repair Levels:\n",
      "    Repair Level  Balanced Accuracy  Statistical Parity Difference  \\\n",
      "0            0.0           0.713419                      -0.086669   \n",
      "1            0.1           0.713671                      -0.085518   \n",
      "2            0.2           0.713671                      -0.085518   \n",
      "3            0.3           0.713923                      -0.084368   \n",
      "4            0.4           0.713923                      -0.084368   \n",
      "5            0.5           0.713923                      -0.084368   \n",
      "6            0.6           0.713671                      -0.085518   \n",
      "7            0.7           0.713671                      -0.085518   \n",
      "8            0.8           0.713419                      -0.084854   \n",
      "9            0.9           0.713419                      -0.084854   \n",
      "10           1.0           0.713419                      -0.084854   \n",
      "\n",
      "    Disparate Impact  Average Odds Difference  Equal Opportunity Difference  \\\n",
      "0           0.697528                -0.043881                     -0.059468   \n",
      "1           0.700341                -0.043119                     -0.059468   \n",
      "2           0.700341                -0.043119                     -0.059468   \n",
      "3           0.703176                -0.042357                     -0.059468   \n",
      "4           0.703176                -0.042357                     -0.059468   \n",
      "5           0.703176                -0.042357                     -0.059468   \n",
      "6           0.700341                -0.043119                     -0.059468   \n",
      "7           0.700341                -0.043119                     -0.059468   \n",
      "8           0.702668                -0.042742                     -0.059468   \n",
      "9           0.702668                -0.042742                     -0.059468   \n",
      "10          0.702668                -0.042742                     -0.059468   \n",
      "\n",
      "    Theil Index  \n",
      "0      0.110644  \n",
      "1      0.110560  \n",
      "2      0.110560  \n",
      "3      0.110476  \n",
      "4      0.110476  \n",
      "5      0.110476  \n",
      "6      0.110560  \n",
      "7      0.110560  \n",
      "8      0.110644  \n",
      "9      0.110644  \n",
      "10     0.110644  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexOfSensitiveAttribute = train.feature_names.index(\"RACE\")\n",
    "repair_levels = np.linspace(0., 1., 11) \n",
    "\n",
    "results = []\n",
    "for repair_level in repair_levels:\n",
    "    print(f\"\\n=== Repair Level: {repair_level} ===\")\n",
    "    \n",
    "    # Apply Disparate Impact Remover with the current repair level\n",
    "    disparate_impact_remover = DisparateImpactRemover(repair_level=repair_level, sensitive_attribute=\"RACE\")\n",
    "    train_transf = disparate_impact_remover.fit_transform(train)\n",
    "    test_transf = disparate_impact_remover.fit_transform(test)\n",
    "    \n",
    "    X_train = train_transf.features\n",
    "    X_train_without_sensitive_attribute = np.delete(X_train, indexOfSensitiveAttribute, axis=1)\n",
    "    y_train = train_transf.labels.ravel()\n",
    "\n",
    "    # Train a classifier on transformed training data\n",
    "    classifier.fit(X_train_without_sensitive_attribute, y_train)\n",
    "\n",
    "    X_test_transf= test_transf.features\n",
    "    X_test_transf_without_sensitive_attribute = np.delete(X_test_transf,\n",
    "                                              indexOfSensitiveAttribute,\n",
    "                                              axis=1)\n",
    "    # Apply the best threshold to the transf test set\n",
    "    test_transf_scores = classifier.predict_proba(X_test_transf_without_sensitive_attribute)[:, 1] #only for the favorable class?\n",
    "    test_transf_LR_predictions= (test_transf_scores >= best_threshold).astype(int)\n",
    "\n",
    "    # Create a copy of the test dataset and set predicted labels\n",
    "    test_transf_with_LR_scores = copy.deepcopy(test)\n",
    "    test_transf_with_LR_scores.labels = test_transf_LR_predictions.reshape(-1, 1)\n",
    "\n",
    "    # Calculate fairness and performance metrics on the test set\n",
    "    test_transf_metric = ClassificationMetric(test, test_transf_with_LR_scores,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "\n",
    "        # Store results for current repair level\n",
    "\n",
    "    true_positive_rate = test_transf_metric.true_positive_rate()\n",
    "    true_negative_rate = test_transf_metric.true_negative_rate()\n",
    "    balanced_accuracy_transf = (true_positive_rate + true_negative_rate) / 2\n",
    "    statistical_parity_difference_transf = test_transf_metric.statistical_parity_difference()\n",
    "    disparate_impact_transf = test_transf_metric.disparate_impact()\n",
    "    average_odds_difference_transf = test_transf_metric.average_odds_difference()\n",
    "    equal_opportunity_difference_transf = test_transf_metric.equal_opportunity_difference()\n",
    "    theil_index_transf = test_transf_metric.theil_index()\n",
    "\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"Repair Level\": repair_level,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_transf,\n",
    "        \"Statistical Parity Difference\": statistical_parity_difference_transf,\n",
    "        \"Disparate Impact\": disparate_impact_transf,\n",
    "        \"Average Odds Difference\": average_odds_difference_transf,\n",
    "        \"Equal Opportunity Difference\": equal_opportunity_difference_transf,\n",
    "        \"Theil Index\": theil_index_transf\n",
    "    })\n",
    "    \n",
    "# Display results for different repair levels\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResults for Various Repair Levels:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results, a repair level around 0.4–0.5 appears to offer the best trade-off between fairness improvements and maintaining Balanced Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity reasons, we will use the repair level = 1 to show the results comparison between original and transformed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\festa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\aif360\\metrics\\dataset_metric.py:82: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    }
   ],
   "source": [
    "# Plot Test Metrics Over Thresholds\n",
    "test_transf_balanced_accs = []\n",
    "test_transf_disp_impacts = []\n",
    "test_transf_avg_odds_diffs = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    test_transf_predictions = (test_transf_scores >= threshold).astype(int)\n",
    "    test_transf_with_scores = copy.deepcopy(test)\n",
    "    test_transf_with_scores.labels = test_transf_predictions.reshape(-1, 1)\n",
    "\n",
    "    test_transf_metric = ClassificationMetric(test, test_transf_with_scores, unprivileged_groups, privileged_groups)\n",
    "    test_transf_balanced_accs.append((test_transf_metric.true_positive_rate() + test_transf_metric.true_negative_rate()) / 2)\n",
    "    test_transf_disp_impacts.append(test_transf_metric.disparate_impact())\n",
    "    test_transf_avg_odds_diffs.append(test_transf_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\festa\\AppData\\Local\\Temp\\ipykernel_25836\\656783206.py:34: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create the figure and primary y-axis for Balanced Accuracy\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Balanced Accuracy\n",
    "ax1.plot(thresholds, test_transf_balanced_accs, label=\"Balanced Accuracy\", color=\"blue\", linewidth=2)\n",
    "ax1.set_xlabel(\"Threshold\", fontsize=14)\n",
    "ax1.set_ylabel(\"Balanced Accuracy\", color=\"blue\", fontsize=14)\n",
    "ax1.tick_params(axis='y', labelcolor=\"blue\")\n",
    "ax1.grid()\n",
    "\n",
    "# Secondary y-axis for Disparate Impact and Equal Opportunity Difference\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Disparate Impact\n",
    "ax2.plot(thresholds, test_transf_disp_impacts, label=\"Disparate Impact\", color=\"orange\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# Average Odds Difference\n",
    "ax2.plot(thresholds, test_transf_avg_odds_diffs, label=\"Average Odds Difference\", color=\"red\", linestyle=\"-.\", linewidth=2)\n",
    "\n",
    "ax2.set_ylabel(\"Fairness Metrics\", color=\"red\", fontsize=14)\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "\n",
    "# Highlight the best threshold\n",
    "ax1.axvline(best_threshold, color='green', linestyle='--', linewidth=2, label=\"Best Threshold\")\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(lines1 + lines2, labels1 + labels2, loc=\"upper center\", bbox_to_anchor=(0.5, -0.1), ncol=3, fontsize=12)\n",
    "\n",
    "# Title and layout adjustments\n",
    "fig.suptitle(\"Test Metrics vs Threshold (transformed test data)\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the metrics with actual calculated values\n",
    "results_data = {\n",
    "    \"Dataset\": [\n",
    "        \"Train\", \"Train\", \"Test\", \"Test\", \n",
    "        \"Train\", \"Train\", \"Test\", \"Test\", \n",
    "        \"Validation\", \"Validation\", \n",
    "        \"Test (Original)\", \"Test (Transformed)\",\n",
    "        \"Test (Original)\", \"Test (Transformed)\",\n",
    "        \"Test (Original)\", \"Test (Transformed)\",\n",
    "        \"Test (Original)\", \"Test (Transformed)\",\n",
    "        \"Test (Original)\", \"Test (Transformed)\",\n",
    "        \"Test (Original)\", \"Test (Transformed)\"\n",
    "    ],\n",
    "    \"Stage\": [\n",
    "        \"Before Transformation\", \"After Transformation\", \n",
    "        \"Before Transformation\", \"After Transformation\",\n",
    "        \"Before Transformation\", \"After Transformation\", \n",
    "        \"Before Transformation\", \"After Transformation\",\n",
    "        \"Best Threshold (Validation)\", \"Best Threshold (Validation)\",\n",
    "        \"After Threshold\", \"After Threshold\", \n",
    "        \"After Threshold\", \"After Threshold\", \n",
    "        \"After Threshold\", \"After Threshold\", \n",
    "        \"After Threshold\", \"After Threshold\", \n",
    "        \"After Threshold\", \"After Threshold\", \n",
    "        \"After Threshold\", \"After Threshold\"\n",
    "    ],\n",
    "    \"Metric\": [\n",
    "        \"Statistical Parity Difference\", \"Statistical Parity Difference\",\n",
    "        \"Statistical Parity Difference\", \"Statistical Parity Difference\",\n",
    "        \"Disparate Impact\", \"Disparate Impact\",\n",
    "        \"Disparate Impact\", \"Disparate Impact\",\n",
    "        \"Threshold\", \"Balanced Accuracy\",\n",
    "        \"Balanced Accuracy\", \"Balanced Accuracy\", \n",
    "        \"Statistical Parity Difference\", \"Statistical Parity Difference\", \n",
    "        \"Disparate Impact\", \"Disparate Impact\",\n",
    "        \"Average Odds Difference\", \"Average Odds Difference\",\n",
    "        \"Equal Opportunity Difference\", \"Equal Opportunity Difference\", \n",
    "        \"Theil Index\", \"Theil Index\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        metric_train.mean_difference(),\n",
    "        metric_train_after.mean_difference(),\n",
    "        metric_test.mean_difference(),\n",
    "        metric_test_after.mean_difference(),\n",
    "        metric_train.disparate_impact(),\n",
    "        metric_train_after.disparate_impact(),\n",
    "        metric_test.disparate_impact(),\n",
    "        metric_test_after.disparate_impact(),\n",
    "        best_threshold,\n",
    "        best_balanced_acc,\n",
    "        balanced_accuracy, balanced_accuracy_transf,\n",
    "        statistical_parity_difference, statistical_parity_difference_transf,\n",
    "        disparate_impact, disparate_impact_transf,\n",
    "        average_odds_difference, average_odds_difference_transf,\n",
    "        equal_opportunity_difference, equal_opportunity_difference_transf,\n",
    "        theil_index, theil_index_transf\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "results_table = pd.DataFrame(results_data)\n",
    "\n",
    "# Display the table\n",
    "#display(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness Metrics Before and After Transformation**\n",
    "- This table represents the fairness metrics (Statistical Parity Difference and Disparate Impact) for both the train and test datasets, before and after applying the transformation.\n",
    "\n",
    "**Validation Metrics for Threshold Selection**\n",
    "- This table contains metrics related to the validation phase, including the best threshold and corresponding balanced accuracy.\n",
    "\n",
    "**Test Metrics After Applying Threshold**\n",
    "- This table summarizes fairness and performance metrics calculated on the test set of the original and transformed dataset after applying the selected threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fairness Metrics Before and After Transformation'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>Before Transformation</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.130954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train</td>\n",
       "      <td>After Transformation</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.130954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>Before Transformation</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.125587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test</td>\n",
       "      <td>After Transformation</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.125587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train</td>\n",
       "      <td>Before Transformation</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.490487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train</td>\n",
       "      <td>After Transformation</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.490487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test</td>\n",
       "      <td>Before Transformation</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.487627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test</td>\n",
       "      <td>After Transformation</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.487627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset                  Stage                         Metric     Value\n",
       "0   Train  Before Transformation  Statistical Parity Difference -0.130954\n",
       "1   Train   After Transformation  Statistical Parity Difference -0.130954\n",
       "2    Test  Before Transformation  Statistical Parity Difference -0.125587\n",
       "3    Test   After Transformation  Statistical Parity Difference -0.125587\n",
       "4   Train  Before Transformation               Disparate Impact  0.490487\n",
       "5   Train   After Transformation               Disparate Impact  0.490487\n",
       "6    Test  Before Transformation               Disparate Impact  0.487627\n",
       "7    Test   After Transformation               Disparate Impact  0.487627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation Metrics for Threshold Selection'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Validation</td>\n",
       "      <td>Best Threshold (Validation)</td>\n",
       "      <td>Threshold</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>Best Threshold (Validation)</td>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.724037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset                        Stage             Metric     Value\n",
       "0  Validation  Best Threshold (Validation)          Threshold  0.460000\n",
       "1  Validation  Best Threshold (Validation)  Balanced Accuracy  0.724037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test Metrics After Applying Threshold On Original and Transformed'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Balanced Accuracy</td>\n",
       "      <td>0.713419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.446640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Statistical Parity Difference</td>\n",
       "      <td>-0.084854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.256456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Disparate Impact</td>\n",
       "      <td>0.702668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Average Odds Difference</td>\n",
       "      <td>-0.381338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Average Odds Difference</td>\n",
       "      <td>-0.042742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Equal Opportunity Difference</td>\n",
       "      <td>-0.343818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Equal Opportunity Difference</td>\n",
       "      <td>-0.059468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Test (Original)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Theil Index</td>\n",
       "      <td>0.108297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Test (Transformed)</td>\n",
       "      <td>After Threshold</td>\n",
       "      <td>Theil Index</td>\n",
       "      <td>0.110644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset            Stage                         Metric  \\\n",
       "0      Test (Original)  After Threshold              Balanced Accuracy   \n",
       "1   Test (Transformed)  After Threshold              Balanced Accuracy   \n",
       "2      Test (Original)  After Threshold  Statistical Parity Difference   \n",
       "3   Test (Transformed)  After Threshold  Statistical Parity Difference   \n",
       "4      Test (Original)  After Threshold               Disparate Impact   \n",
       "5   Test (Transformed)  After Threshold               Disparate Impact   \n",
       "6      Test (Original)  After Threshold        Average Odds Difference   \n",
       "7   Test (Transformed)  After Threshold        Average Odds Difference   \n",
       "8      Test (Original)  After Threshold   Equal Opportunity Difference   \n",
       "9   Test (Transformed)  After Threshold   Equal Opportunity Difference   \n",
       "10     Test (Original)  After Threshold                    Theil Index   \n",
       "11  Test (Transformed)  After Threshold                    Theil Index   \n",
       "\n",
       "       Value  \n",
       "0   0.707692  \n",
       "1   0.713419  \n",
       "2  -0.446640  \n",
       "3  -0.084854  \n",
       "4   0.256456  \n",
       "5   0.702668  \n",
       "6  -0.381338  \n",
       "7  -0.042742  \n",
       "8  -0.343818  \n",
       "9  -0.059468  \n",
       "10  0.108297  \n",
       "11  0.110644  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Separate the data into three groups\n",
    "fairness_metrics = results_table.iloc[0:8].reset_index(drop=True)\n",
    "validation_metrics = results_table.iloc[8:10].reset_index(drop=True)\n",
    "test_metrics = results_table.iloc[10:22].reset_index(drop=True)\n",
    "\n",
    "# Name the tables\n",
    "fairness_metrics.name = \"Fairness Metrics Before and After Transformation\"\n",
    "validation_metrics.name = \"Validation Metrics for Threshold Selection\"\n",
    "test_metrics.name = \"Test Metrics After Applying Threshold On Original and Transformed\"\n",
    "\n",
    "# Display the tables with their names\n",
    "for table in [fairness_metrics, validation_metrics, test_metrics]:\n",
    "    display(table.name)\n",
    "    display(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "-   Statistical Parity Difference and Disparate Impact are fairness metrics that evaluate the distribution of the **outcome labels** between privileged and unprivileged groups.\n",
    "At the preprocessing stage (where we apply the Disparate Impact Remover), the labels (outcomes) of the dataset remain unchanged. The Disparate Impact Remover only modifies features, not the labels. Since the labels are not affected, these metrics do not change.\n",
    "\n",
    "- In the final stage, after training the classifier, fairness metrics change significantly. This is because the predictions of the model are now based on the transformed features.The transformed features make the model less biased, leading to changes in the predicted outcomes, and thus, the fairness metrics improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
